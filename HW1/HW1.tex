%Do not alter this block of commands.  If you're proficient at LaTeX, you may include additional packages, create macros, etc. immediately below this block of commands, but make sure to NOT alter the header, margin, and comment settings here. 
\documentclass[12pt]{article}
 \usepackage[margin=1in, bottom=4.5cm]{geometry}
\usepackage{amsmath,amsthm,amssymb,amsfonts, enumitem, fancyhdr, color, comment, graphicx, environ, scrextend}
\pagestyle{fancy}
\setlength{\headheight}{65pt}
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{sol}
    {\emph{Proof.}
    }
    {
    \qed
    }
\specialcomment{com}{ \color{blue} \textbf{Comment:} }{\color{black}} %for instructor comments while grading
\NewEnviron{probscore}{\marginpar{ \color{blue} \tiny Problem Score: \BODY \color{black} }}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand\restr[2]{{% we make the whole thing an ordinary symbol
  \left.\kern-\nulldelimiterspace % automatically resize the bar with \right
  #1 % the function
  \vphantom{\big|} % pretend it's a little taller at normal size
  \right|_{#2} % this is the delimiter
  }}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Fill in the appropriate information below
\lhead{Trey Manuszak}  %replace with your name
\rhead{MAT 473: Intermediate Real Analysis II \\ Homework 1: 1, 2, 3, 4} %replace XYZ with the homework course number, semester (e.g. ``Spring 2019"), and assignment number.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{blindtext}
\title{MAT 473: Intermediate Real Analysis II}
\date{January 23, 2020}
\author{Trey Manuszak\\ Arizona State University}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Do not alter this block.
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\maketitle
\newpage



%Copy the following block of text for each problem in the assignment.
\begin{problem}{1} Let $f: \mathbb{R}^2 \to \mathbb{R}$ be given by $$f(x) = \begin{cases} 
      \frac{\left|x_1\right|^a \left|x_2\right|^b}{\lVert x \rVert^c}, & \text{if } x \neq 0 \\
      0, & \text{if } x = 0, 
   \end{cases}
$$ where $a,b,$ and $c$ are positive real numbers. Prove that $\lim_{x \to 0} f(x)$ exists if and only if $a + b > c$.
\end{problem}
\begin{sol}
$(\Longrightarrow):$ Suppose $a + b > c$. Then clearly $a+b-c > 0$. Then for all $x \in \mathbb{R}^2$, we have \begin{align*}
    \left|\frac{\left| x_1 \right|^a\left|x_2\right|^b}{\lVert x \rVert^c} - 0\right| &= \frac{\left| x_1 \right|^a\left|x_2\right|^b}{\lVert x \rVert^c} \\ &\leq \frac{\lVert x \rVert ^a \lVert x \rVert^b}{\lVert x \rVert^c} \tag*{(By the fundamental inequalities)} \\ &= \lVert x \rVert^{a + b - c}.
\end{align*} Since $a+b-c > 0$, $\lVert x \rVert^{a+b-c}$ converges to $0$ as $x$ converges to $0$, and thus by the squeeze theorem, $\left| f(x) - 0 \right| = \left|\frac{\left| x_1 \right|^a\left|x_2\right|^b}{\lVert x \rVert^c} - 0\right|$ converges to $0$, and thus $\lim_{x \to 0} f(x) = 0$.

$(\Longleftarrow):$ Proof by contrapositive. We'll show that if $a + b \leq c$, then $\lim_{x \to 0}f(x)$ does not exist. 

\underline{Case 1}: Suppose $a + b < c$. Consider $Z = \{(t, t) : t \in \mathbb{R}^+\}$. Then, \begin{align*}
    \lim_{x \to 0}\restr{f}{Z}(x) &= \lim_{t \to 0^+} \frac{\left| t \right|^a \left| t \right|^b}{\sqrt{t^2 + t^2}^c} \\ &=\lim_{t \to 0^+} \frac{t^a+b}{(\sqrt{2}t)^c} \\ &= \lim_{t \to 0^+} \frac{1}{(\sqrt{2}t)^{c-a-b}} \\ &= \infty. \tag*{(Since $c - a - b > 0$)}
\end{align*}
Thus, $\lim_{x \to 0}\restr{f}{Z}(x)$ does not exist, which implies $\lim_{x \to 0}f(x)$ does not exist.

\underline{Case 2}: Suppose $a + b = c$. Consider $Z_1 = \{(t,0) : t \in \mathbb{R}^+\}$. Then we have, \begin{align*}
    \lim_{x \to 0}\restr{f}{Z_1}(x) &= \lim_{t \to 0^+}\frac{\left| t \right|^a \left| 0 \right|^b}{\sqrt{t^2 + 0}^c} \\ &= \lim_{t \to 0^+}\frac{0}{t^c} \\ &= 0.
\end{align*}
Now consider $Z_2 = \{(t,t) : t \in \mathbb{R}^+\}$. Then, \begin{align*}
    \lim_{x \to 0}\restr{f}{Z_2}(x) &= \lim_{t \to 0^+}\frac{\left| t \right|^a \left| t \right|^b}{\sqrt{t^2 + 0}^c} \\ &= \lim_{t \to 0^+}\frac{t^{a+b}}{\sqrt{2}^ct^c} \\ &= \lim_{t \to 0^+} \frac{t^{a+b-c}}{\sqrt{2}^c} \\ &= \lim_{t \to 0^+} \frac{t^0}{\sqrt{2}^c} \tag*{(Since $a+b=c$)} \\ &= \frac{1}{\sqrt{2}^c}.
\end{align*}
Thus, $\lim_{x \to 0}\restr{f}{Z_1}(x) = 0 \neq \frac{1}{\sqrt{2}^c} = \lim_{x \to 0}\restr{f}{Z_2}(x)$. Thus, $\lim_{x \to 0}f(x)$ does not exist. Therefore, in all cases, $\lim_{x \to 0}f(x)$ does not exist.
\end{sol}

\begin{problem}{2}
Let $f : \mathbb{R}^2 \to \mathbb{R}$ be given by $$f(x) = \begin{cases} 
      \frac{x_1x_2^3}{x_1^2 + x_2^6}, & \text{if } x \neq 0 \\
      0, & \text{if } x = 0.
   \end{cases}
$$ Prove that $\lim_{x \to 0} f(x)$ does not exist.
\end{problem}
\begin{sol}
Suppose $f : \mathbb{R}^2 \setminus \{0\} \to \mathbb{R}$. Let $Z_1 = \{(u,0)^t : u \in \mathbb{R} \setminus \{0\}\}$ and $Z_2 = \{(u^3, u)^T : u \in \mathbb{R} \setminus \{0\}\}$. We have 
\begin{align*} f(u,0) &= \frac{u \cdot 0^3}{u^2 + 0^6} = \frac{0}{u^2} = 0 \\ f(u^3,u) &= \frac{u^3 \cdot u^3}{u^6 + u^6} = \frac{u^6}{2u^6} = \frac{1}{2}.
\end{align*} Thus, $\lim_{x \to 0} \restr{f}{Z_1}(x) = 0 \neq \frac{1}{2} = \lim_{x \to 0} \restr{f}{Z_2}(x)$. Therefore, $\lim_{x \to 0} f(x)$ does not exist.
\end{sol}

\begin{problem}{3}
Let $f : \mathbb{R}^n \to \mathbb{R}^m$ be a linear function.
\begin{itemize}
    \item[(a)]

Prove that $\frac{f(x)}{\lVert x \rVert}$ is a bounded function of $x$ on $\mathbb{R}^n \setminus \{0\}$. (Hint: if $f$ is represented by a matrix, then $f(x)$ equals a linear combination of the columns of that matrix.)

\vspace{1em}

\begin{sol}
Define $g:\mathbb{R}^n \setminus \{0\} \to \mathbb{R}^m$ by $g(x) = \frac{f(x)}{\lVert x \rVert}$ for all $x \in \mathbb{R}^n \setminus \{0\}$. Let $x \in \mathbb{R}^n \setminus \{0\}$. Then, \begin{align*}
    \Bigg\lVert \frac{\sum_{i = 1}^m \left( \sum_{j = 1}^n f_i (e_j^{(n)})x_j\right)e_i^{(m)}}{\lVert x \rVert} \Bigg\rVert &\leq \sum_{i = 1}^m \left| \frac{\left( \sum_{j = 1}^n f_i(e_j^{(n)})x_j \right)}{\lVert x \rVert} \right| \\ &\leq \frac{\sum_{i = 1}^m \sum_{j = 1}^n \left| f_i(e_j^{(n)}) \right| \left| x_j \right|}{\lVert x \rVert} \\ &\leq \frac{\sum_{i = 1}^m \sum_{j = 1}^n \left| f_i(e_j^{(n)}) \right| \lVert x \rVert}{\lVert x \rVert} \\ &= \sum_{i = 1}^m \sum_{j = 1}^n \left| f_i(e_j^{(n)}) \right| < \infty.
\end{align*}
Thus, $\frac{f(x)}{\lVert x \rVert}$ is bounded.
\end{sol}

    \item[(b)] Suppose that $f$ is not the zero map. Prove that $\lim_{x \to 0} \frac{f(x)}{\lVert x \rVert}$ does not exist. (Hint: if $f(v) \neq 0$ consider $x = tv$ for $t \in \mathbb{R} \setminus \{0\}.)$
    
    \begin{sol}
    Let $f : \mathbb{R}^n \to \mathbb{R}^m$ be a linear function that is not the zero map. Fix $v \in \mathbb{R}^n$ such that $f(v) \neq 0$. Let $Z_1 = \{kv : k \in \mathbb{R}^+\}$ and $Z_2 = \{kv : k \in \mathbb{R}^-\}$. Then, \begin{align*}
        \lim_{x \to 0} \frac{\restr{f}{Z_1}(x)}{\lVert x \rVert} &= \lim_{t \to 0^+} \frac{\restr{f}{Z_1}(tv)}{\lVert t v \rVert} \\
        &= \lim_{t \to 0^+} \frac{t\restr{f}{Z_1}(v)}{\left| t \right| \lVert v \rVert} \\
        &= \frac{\restr{f}{Z_1}(v)}{\lVert v \rVert} \cdot \lim_{t \to 0^+} \frac{t}{\left| t \right|} \\ &=  \frac{\restr{f}{Z_1}(v)}{\lVert v \rVert} \\ &> 0
    \end{align*} and \begin{align*}
        \lim_{x \to 0} \frac{\restr{f}{Z_2}(x)}{\lVert x \rVert} &= \lim_{t \to 0^-} \frac{\restr{f}{Z_2}(tv)}{\lVert t v \rVert} \\
        &= \lim_{t \to 0^-} \frac{t\restr{f}{Z_2}(v)}{\left| t \right| \lVert v \rVert} \\
        &= \frac{\restr{f}{Z_2}(v)}{\lVert v \rVert} \cdot \lim_{t \to 0^-} \frac{t}{\left| t \right|} \\ &=  \frac{-\restr{f}{Z_2}(v)}{\lVert v \rVert} \\ &< 0.
    \end{align*}
    Thus, the limit does not exist.
    \end{sol}
\end{itemize}

\end{problem}

\begin{problem}{4}
Let $V$ and $W$ be normed vector spaces. Recall that $B(V,W) = \{T \in L(V,W) : \text{sup}_{\lVert x \rVert \leq 1} \lVert Tx \rVert < \infty\}$. 

\begin{itemize}
    \item[(a)] Prove that $B(V,W)$ is a vector space.
    
    \begin{sol}
    Let $V$ and $W$ be normed vector spaces. First, we'll show that $L(V,W)$ is a vector space. Suppose $T_1,T_2,T_3 \in L(V,W)$ and $\alpha, \beta \in \mathbb{K}$ and $x \in V$. Note, $L(V,W)$ is clearly closed from Definition 2.1. This leaves the following properties. \begin{itemize}
        \item[(1)] Commutativity: \begin{align*}
            (T_1 +_L T_2)(x) &= T_1x +_W T_2x \tag*{(Addition on $L(V,W)$)} \\ &= T_2x +_W T_1x \tag*{(Commutativity of addition in $W$)} \\ &= (T_2 +_L T_1)(x). \tag*{(Addition on $L(V,W)$)}
        \end{align*}
        \item[(2)] Associativity: \begin{align*}
            (T_1 +_L (T_2 +_L T_3))(x) &= T_1x +_W (T_2 +_L T_3)(x) \tag*{(Addition on $L(V,W)$)} \\ &= T_1x +_W (T_2x +_W T_3x) \tag*{(Addition on $L(V,W)$)} \\ &= (T_1x +_W T_2x) +_W T_3x \tag*{(Associativity in $W$)} \\ &= (T_1 +_L T_2)(x) +_W T_3x \tag*{(Addition on $L(V,W)$)} \\ &= ((T_1 +_L T_2) +_L T_3)(x). \tag*{(Addition on $L(V,W)$)}
        \end{align*}
        \item[(3)] Zero:  Let $0_L \in L(V,W)$ be the zero map. \begin{align*}
            (T_1 +_L 0_L)(x) &= T_1x +_W 0_Lx  \tag*{(Addition on $L(V,W)$)} \\ &= T_1x +_W 0_W \tag*{(Definition of zero map)} \\ &= T_1x. \tag*{(Addition of $0_W$)}
        \end{align*}
        \item[(4)] Additive inverse: Define $-T_1:V \to W$ by $-T_1(v) = T_1(-v)$ for all $v \in V$. Then, \begin{align*}
            (T_1 +_L -T_1)(x) &= T_1x +_W -T_1x \\ &= -T_1x +_W T_1-x \\ &= T_1(x +_V(-x))  \tag*{(Linearity of $T_1$)} \\ &= T_1 \cdot 0_V \tag*{(Addititive inverse in $V$)} \\ &= 0_W. \tag*{(Linearity of $T_1$)}
        \end{align*}
        Since $x \in V$ was arbitrary, this is true for all $x \in V$. Thus, $T_1 +_L -T_1 = 0_L$.
        \item[(5)] Multiplication over $\mathbb{K}$: \begin{align*}
            \alpha \cdot (\beta \cdot T_1 (x)) &= \alpha \cdot (\beta T_1x) \tag*{(Definition of $T_1$)} \\ &= \alpha \beta (T_1x) \tag*{(Multiplication over $\mathbb{K}$ in $W$)} \\ &= ((\alpha \beta ) \cdot T_1)(x). \tag*{(Definition of $T_1$)}
        \end{align*}
        \item[(6)] Unit of scalar multiplication: \begin{align*}
            (1 \cdot T_1)(x) &= 1 \cdot T_1(x) \tag*{(Linearity of scalar multiplication)} \\ &= T(x). \tag*{(Definition of 1)}
        \end{align*}
        \item[(7)] Distribution of scalar multiples: \begin{align*}
            (\alpha(T_1 +_L T_2))(x) &= \alpha((T_1 +_L T_2)(x)) \tag*{(Linearity of scalar multiplication)} \\ &= \alpha (T_1x +_W T_2x) \tag*{(Addition on $L(V,W)$)} \\ &= \alpha T_1x +_W \alpha T_2x \tag*{(Distribution of scalar multiples on $W$)} \\ (\alpha T_1 +_L \alpha T_2)(x) &= (\alpha T_1)x +_W (\alpha T_2)x \tag*{(Addition on $L(V,W)$)} \\ &= \alpha T_1x +_W \alpha T_2x. \tag*{(Scalar multiplication on $L(V,W)$)}
        \end{align*}
    \end{itemize} 
    Therefore, $L(V,W)$ is a vector space. 
    
    \hspace{1em} Now, we'll show $B(V,W)$ is closed and thus a subspace of $L(V,W)$. Let $T_1, T_2 \in B(V,W)$ and $\alpha, \beta \in \mathbb{K}$ and $x \in V$. Then, \begin{align*}
        \sup_{\lVert x \rVert \leq 1} \lVert (\alpha T_1 +_B \beta T_2)(x) \rVert &\leq \sup_{\lVert x \rVert \leq 1} (\left| \alpha \right| \lVert T_1x \rVert + \left| \beta \right| \lVert T_2x \rVert) \tag*{(By triangle inequality)} \\ &\leq \left| \alpha \right| \sup_{\lVert x \rVert \leq 1} \lVert T_1x \rVert + \left| \beta \right| \sup_{\lVert x \rVert \leq 1} \lVert T_2x \rVert \tag*{(Definition of supremum)} \\ &= \left| \alpha \right| \lVert T_1 \rVert + \left| \beta \right| \lVert T_2 \rVert \tag*{(Definition of $\lVert T_1 \rVert$ and $\lVert T_2 \rVert$)} \\ &< \infty.
    \end{align*}
    Thus, $(\alpha T_1 +_B \beta T_2) \in B(V,W)$, which implies $B(V,W)$ is a subspace of $L(V,W)$. Therefore, $B(V,W)$ is a vector space.
    \end{sol}
    
    \item[(b)] For $T \in B(V,W)$, let $\lVert T \rVert = \text{sup}_{\lVert x \rVert \leq 1} \lVert Tx \rVert$. Prove that $\lVert \cdot \rVert$ is a norm on $B(V,W)$.
    
    \begin{sol}
    Since $\lVert T_1x \rVert_W \geq 0$ for all $x \in V$ by positivity of $\lVert \cdot \rVert_W$, we have $\sup_{\lVert x \rVert \leq 1} \lVert T_1x \rVert_W \geq 0$. Now suppose $\lVert T_1 \rVert = 0$. Then $\sup_{\lVert x \rVert \leq 1} \lVert T_1x \rVert = 0$. Suppose to the contrary there exists $v \in V$ such that $\lVert T_1v \rVert > 0$. Then since $\sup_{\lVert x \rVert \leq 1} \lVert T_1x \rVert = 0$, $\lVert v \rVert > 1$. But then $\lVert \frac{v}{\lVert v \rVert} \rVert = 1$, so $\lVert T_1 \frac{v}{\lVert v \rVert} \rVert = 0$. But, then $\lVert T_1 \frac{v}{\lVert v \rVert} \rVert = \left| \frac{1}{\lVert v \rVert} \right| \lVert T_1v \rVert = 0$, which implies $\lVert T_1v \rVert = 0$. This is a contradiction. Therefore, $T_1$ is the zero map and we have positivity of $\lVert \cdot \rVert$.
    
    \hspace{1 em} Next, \begin{align*}
        \lVert \alpha T_1 \rVert &= \sup_{\lVert x \rVert \leq 1} \lVert \alpha T_1x \rVert \tag*{(Definition of $\lVert \alpha T_1 \rVert$)} \\ &= \left| \alpha \right| \sup_{\lVert x \rVert \leq 1} \lVert T_1x \rVert \tag*{(Homogeneity of supremum norm)} \\ &= \left| \alpha \right| \lVert T_1 \rVert. \tag*{(Definition of $\lVert T_1 \rVert$)}
    \end{align*} 
    Thus, we have homogeneity of $\lVert \cdot \rVert$. 
    
    \hspace{1 em} Lastly, \begin{align*}
        \lVert T_1 +_B T_2 \rVert &= \sup_{\lVert x \rVert \leq 1} \lVert (T_1 +_B T_2)(x) \rVert \tag*{(Definition of $\lVert T_1 +_B T_2 \rVert$)} \\ &\leq \sup_{\lVert x \rVert \leq 1} (\lVert T_1x \rVert + \lVert T_2x \rVert ) \tag*{(Triangle inequality of the norm on $W$)} \\ &\leq \sup_{\lVert x \rVert \leq 1} \lVert T_1x \rVert + \sup_{\lVert x \rVert \leq 1} \lVert T_2x \rVert \tag*{(Property of supremum norm)} \\ &= \lVert T_1 \rVert + \lVert T_2 \rVert. \tag*{(Definition of $\lVert T_1 \rVert$ and $\lVert T_2 \rVert$)}
    \end{align*}
    Thus, we have the triangle inequality of $\lVert \cdot \rVert$. Therefore, $\lVert \cdot \rVert$ is a norm on $B(V,W)$.
    \end{sol}
\end{itemize}
\end{problem}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Do not alter anything below this line.
\end{document}